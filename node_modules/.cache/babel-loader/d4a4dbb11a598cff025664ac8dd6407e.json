{"ast":null,"code":"// Copyright 2019 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     https://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n'use strict';\n\nvar _classCallCheck = require(\"/Users/Wangmei/Desktop/cmu/capstone/ASRproto/asr-proto/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/Wangmei/Desktop/cmu/capstone/ASRproto/asr-proto/node_modules/@babel/runtime/helpers/createClass\");\n\nvar gapicConfig = require('./speech_client_config.json');\n\nvar gax = require('google-gax');\n\nvar merge = require('lodash.merge');\n\nvar path = require('path');\n\nvar protobuf = require('protobufjs');\n\nvar VERSION = require('../../package.json').version;\n/**\n * Service that implements Google Cloud Speech API.\n *\n * @class\n * @memberof v1p1beta1\n */\n\n\nvar SpeechClient =\n/*#__PURE__*/\nfunction () {\n  /**\n   * Construct an instance of SpeechClient.\n   *\n   * @param {object} [options] - The configuration object. See the subsequent\n   *   parameters for more details.\n   * @param {object} [options.credentials] - Credentials object.\n   * @param {string} [options.credentials.client_email]\n   * @param {string} [options.credentials.private_key]\n   * @param {string} [options.email] - Account email address. Required when\n   *     using a .pem or .p12 keyFilename.\n   * @param {string} [options.keyFilename] - Full path to the a .json, .pem, or\n   *     .p12 key downloaded from the Google Developers Console. If you provide\n   *     a path to a JSON file, the projectId option below is not necessary.\n   *     NOTE: .pem and .p12 require you to specify options.email as well.\n   * @param {number} [options.port] - The port on which to connect to\n   *     the remote host.\n   * @param {string} [options.projectId] - The project ID from the Google\n   *     Developer's Console, e.g. 'grape-spaceship-123'. We will also check\n   *     the environment variable GCLOUD_PROJECT for your project ID. If your\n   *     app is running in an environment which supports\n   *     {@link https://developers.google.com/identity/protocols/application-default-credentials Application Default Credentials},\n   *     your project ID will be detected automatically.\n   * @param {function} [options.promise] - Custom promise module to use instead\n   *     of native Promises.\n   * @param {string} [options.servicePath] - The domain name of the\n   *     API remote host.\n   */\n  function SpeechClient(opts) {\n    var _this = this;\n\n    _classCallCheck(this, SpeechClient);\n\n    this._descriptors = {}; // Ensure that options include the service address and port.\n\n    opts = Object.assign({\n      clientConfig: {},\n      port: this.constructor.port,\n      servicePath: this.constructor.servicePath\n    }, opts); // Create a `gaxGrpc` object, with any grpc-specific options\n    // sent to the client.\n\n    opts.scopes = this.constructor.scopes;\n    var gaxGrpc = new gax.GrpcClient(opts); // Save the auth object to the client, for use by other methods.\n\n    this.auth = gaxGrpc.auth; // Determine the client header string.\n\n    var clientHeader = [\"gl-node/\".concat(process.version), \"grpc/\".concat(gaxGrpc.grpcVersion), \"gax/\".concat(gax.version), \"gapic/\".concat(VERSION)];\n\n    if (opts.libName && opts.libVersion) {\n      clientHeader.push(\"\".concat(opts.libName, \"/\").concat(opts.libVersion));\n    } // Load the applicable protos.\n\n\n    var protos = merge({}, gaxGrpc.loadProto(path.join(__dirname, '..', '..', 'protos'), 'google/cloud/speech/v1p1beta1/cloud_speech.proto')); // Some of the methods on this service provide streaming responses.\n    // Provide descriptors for these.\n\n    this._descriptors.stream = {\n      streamingRecognize: new gax.StreamDescriptor(gax.StreamType.BIDI_STREAMING)\n    };\n    var protoFilesRoot = new gax.GoogleProtoFilesRoot();\n    protoFilesRoot = protobuf.loadSync(path.join(__dirname, '..', '..', 'protos', 'google/cloud/speech/v1p1beta1/cloud_speech.proto'), protoFilesRoot); // This API contains \"long-running operations\", which return a\n    // an Operation object that allows for tracking of the operation,\n    // rather than holding a request open.\n\n    this.operationsClient = new gax.lro({\n      auth: gaxGrpc.auth,\n      grpc: gaxGrpc.grpc\n    }).operationsClient(opts);\n    var longRunningRecognizeResponse = protoFilesRoot.lookup('google.cloud.speech.v1p1beta1.LongRunningRecognizeResponse');\n    var longRunningRecognizeMetadata = protoFilesRoot.lookup('google.cloud.speech.v1p1beta1.LongRunningRecognizeMetadata');\n    this._descriptors.longrunning = {\n      longRunningRecognize: new gax.LongrunningDescriptor(this.operationsClient, longRunningRecognizeResponse.decode.bind(longRunningRecognizeResponse), longRunningRecognizeMetadata.decode.bind(longRunningRecognizeMetadata))\n    }; // Put together the default options sent with requests.\n\n    var defaults = gaxGrpc.constructSettings('google.cloud.speech.v1p1beta1.Speech', gapicConfig, opts.clientConfig, {\n      'x-goog-api-client': clientHeader.join(' ')\n    }); // Set up a dictionary of \"inner API calls\"; the core implementation\n    // of calling the API is handled in `google-gax`, with this code\n    // merely providing the destination and request information.\n\n    this._innerApiCalls = {}; // Put together the \"service stub\" for\n    // google.cloud.speech.v1p1beta1.Speech.\n\n    var speechStub = gaxGrpc.createStub(protos.google.cloud.speech.v1p1beta1.Speech, opts); // Iterate over each of the methods that the service provides\n    // and create an API call method for each.\n\n    var speechStubMethods = ['recognize', 'longRunningRecognize', 'streamingRecognize'];\n\n    var _loop = function _loop() {\n      var methodName = _speechStubMethods[_i];\n      _this._innerApiCalls[methodName] = gax.createApiCall(speechStub.then(function (stub) {\n        return function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          return stub[methodName].apply(stub, args);\n        };\n      }, function (err) {\n        return function () {\n          throw err;\n        };\n      }), defaults[methodName], _this._descriptors.stream[methodName] || _this._descriptors.longrunning[methodName]);\n    };\n\n    for (var _i = 0, _speechStubMethods = speechStubMethods; _i < _speechStubMethods.length; _i++) {\n      _loop();\n    }\n  }\n  /**\n   * The DNS address for this API service.\n   */\n\n\n  _createClass(SpeechClient, [{\n    key: \"getProjectId\",\n\n    /**\n     * Return the project ID used by this class.\n     * @param {function(Error, string)} callback - the callback to\n     *   be called with the current project Id.\n     */\n    value: function getProjectId(callback) {\n      return this.auth.getProjectId(callback);\n    } // -------------------\n    // -- Service calls --\n    // -------------------\n\n    /**\n     * Performs synchronous speech recognition: receive results after all audio\n     * has been sent and processed.\n     *\n     * @param {Object} request\n     *   The request object that will be sent.\n     * @param {Object} request.config\n     *   *Required* Provides information to the recognizer that specifies how to\n     *   process the request.\n     *\n     *   This object should have the same structure as [RecognitionConfig]{@link google.cloud.speech.v1p1beta1.RecognitionConfig}\n     * @param {Object} request.audio\n     *   *Required* The audio data to be recognized.\n     *\n     *   This object should have the same structure as [RecognitionAudio]{@link google.cloud.speech.v1p1beta1.RecognitionAudio}\n     * @param {Object} [options]\n     *   Optional parameters. You can override the default settings for this call, e.g, timeout,\n     *   retries, paginations, etc. See [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions} for the details.\n     * @param {function(?Error, ?Object)} [callback]\n     *   The function which will be called with the result of the API call.\n     *\n     *   The second parameter to the callback is an object representing [RecognizeResponse]{@link google.cloud.speech.v1p1beta1.RecognizeResponse}.\n     * @returns {Promise} - The promise which resolves to an array.\n     *   The first element of the array is an object representing [RecognizeResponse]{@link google.cloud.speech.v1p1beta1.RecognizeResponse}.\n     *   The promise has a method named \"cancel\" which cancels the ongoing API call.\n     *\n     * @example\n     *\n     * const speech = require('speech.v1p1beta1');\n     *\n     * const client = new speech.v1p1beta1.SpeechClient({\n     *   // optional auth parameters.\n     * });\n     *\n     * const encoding = 'FLAC';\n     * const sampleRateHertz = 44100;\n     * const languageCode = 'en-US';\n     * const config = {\n     *   encoding: encoding,\n     *   sampleRateHertz: sampleRateHertz,\n     *   languageCode: languageCode,\n     * };\n     * const uri = 'gs://bucket_name/file_name.flac';\n     * const audio = {\n     *   uri: uri,\n     * };\n     * const request = {\n     *   config: config,\n     *   audio: audio,\n     * };\n     * client.recognize(request)\n     *   .then(responses => {\n     *     const response = responses[0];\n     *     // doThingsWith(response)\n     *   })\n     *   .catch(err => {\n     *     console.error(err);\n     *   });\n     */\n\n  }, {\n    key: \"recognize\",\n    value: function recognize(request, options, callback) {\n      if (options instanceof Function && callback === undefined) {\n        callback = options;\n        options = {};\n      }\n\n      options = options || {};\n      return this._innerApiCalls.recognize(request, options, callback);\n    }\n    /**\n     * Performs asynchronous speech recognition: receive results via the\n     * google.longrunning.Operations interface. Returns either an\n     * `Operation.error` or an `Operation.response` which contains\n     * a `LongRunningRecognizeResponse` message.\n     *\n     * @param {Object} request\n     *   The request object that will be sent.\n     * @param {Object} request.config\n     *   *Required* Provides information to the recognizer that specifies how to\n     *   process the request.\n     *\n     *   This object should have the same structure as [RecognitionConfig]{@link google.cloud.speech.v1p1beta1.RecognitionConfig}\n     * @param {Object} request.audio\n     *   *Required* The audio data to be recognized.\n     *\n     *   This object should have the same structure as [RecognitionAudio]{@link google.cloud.speech.v1p1beta1.RecognitionAudio}\n     * @param {Object} [options]\n     *   Optional parameters. You can override the default settings for this call, e.g, timeout,\n     *   retries, paginations, etc. See [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions} for the details.\n     * @param {function(?Error, ?Object)} [callback]\n     *   The function which will be called with the result of the API call.\n     *\n     *   The second parameter to the callback is a [gax.Operation]{@link https://googleapis.github.io/gax-nodejs/Operation} object.\n     * @returns {Promise} - The promise which resolves to an array.\n     *   The first element of the array is a [gax.Operation]{@link https://googleapis.github.io/gax-nodejs/Operation} object.\n     *   The promise has a method named \"cancel\" which cancels the ongoing API call.\n     *\n     * @example\n     *\n     * const speech = require('speech.v1p1beta1');\n     *\n     * const client = new speech.v1p1beta1.SpeechClient({\n     *   // optional auth parameters.\n     * });\n     *\n     * const encoding = 'FLAC';\n     * const sampleRateHertz = 44100;\n     * const languageCode = 'en-US';\n     * const config = {\n     *   encoding: encoding,\n     *   sampleRateHertz: sampleRateHertz,\n     *   languageCode: languageCode,\n     * };\n     * const uri = 'gs://bucket_name/file_name.flac';\n     * const audio = {\n     *   uri: uri,\n     * };\n     * const request = {\n     *   config: config,\n     *   audio: audio,\n     * };\n     *\n     * // Handle the operation using the promise pattern.\n     * client.longRunningRecognize(request)\n     *   .then(responses => {\n     *     const [operation, initialApiResponse] = responses;\n     *\n     *     // Operation#promise starts polling for the completion of the LRO.\n     *     return operation.promise();\n     *   })\n     *   .then(responses => {\n     *     const result = responses[0];\n     *     const metadata = responses[1];\n     *     const finalApiResponse = responses[2];\n     *   })\n     *   .catch(err => {\n     *     console.error(err);\n     *   });\n     *\n     * const encoding = 'FLAC';\n     * const sampleRateHertz = 44100;\n     * const languageCode = 'en-US';\n     * const config = {\n     *   encoding: encoding,\n     *   sampleRateHertz: sampleRateHertz,\n     *   languageCode: languageCode,\n     * };\n     * const uri = 'gs://bucket_name/file_name.flac';\n     * const audio = {\n     *   uri: uri,\n     * };\n     * const request = {\n     *   config: config,\n     *   audio: audio,\n     * };\n     *\n     * // Handle the operation using the event emitter pattern.\n     * client.longRunningRecognize(request)\n     *   .then(responses => {\n     *     const [operation, initialApiResponse] = responses;\n     *\n     *     // Adding a listener for the \"complete\" event starts polling for the\n     *     // completion of the operation.\n     *     operation.on('complete', (result, metadata, finalApiResponse) => {\n     *       // doSomethingWith(result);\n     *     });\n     *\n     *     // Adding a listener for the \"progress\" event causes the callback to be\n     *     // called on any change in metadata when the operation is polled.\n     *     operation.on('progress', (metadata, apiResponse) => {\n     *       // doSomethingWith(metadata)\n     *     });\n     *\n     *     // Adding a listener for the \"error\" event handles any errors found during polling.\n     *     operation.on('error', err => {\n     *       // throw(err);\n     *     });\n     *   })\n     *   .catch(err => {\n     *     console.error(err);\n     *   });\n     *\n     * const encoding = 'FLAC';\n     * const sampleRateHertz = 44100;\n     * const languageCode = 'en-US';\n     * const config = {\n     *   encoding: encoding,\n     *   sampleRateHertz: sampleRateHertz,\n     *   languageCode: languageCode,\n     * };\n     * const uri = 'gs://bucket_name/file_name.flac';\n     * const audio = {\n     *   uri: uri,\n     * };\n     * const request = {\n     *   config: config,\n     *   audio: audio,\n     * };\n     *\n     * // Handle the operation using the await pattern.\n     * const [operation] = await client.longRunningRecognize(request);\n     *\n     * const [response] = await operation.promise();\n     */\n\n  }, {\n    key: \"longRunningRecognize\",\n    value: function longRunningRecognize(request, options, callback) {\n      if (options instanceof Function && callback === undefined) {\n        callback = options;\n        options = {};\n      }\n\n      options = options || {};\n      return this._innerApiCalls.longRunningRecognize(request, options, callback);\n    }\n    /**\n     * Performs bidirectional streaming speech recognition: receive results while\n     * sending audio. This method is only available via the gRPC API (not REST).\n     *\n     * @param {Object} [options]\n     *   Optional parameters. You can override the default settings for this call, e.g, timeout,\n     *   retries, paginations, etc. See [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions} for the details.\n     * @returns {Stream}\n     *   An object stream which is both readable and writable. It accepts objects\n     *   representing [StreamingRecognizeRequest]{@link google.cloud.speech.v1p1beta1.StreamingRecognizeRequest} for write() method, and\n     *   will emit objects representing [StreamingRecognizeResponse]{@link google.cloud.speech.v1p1beta1.StreamingRecognizeResponse} on 'data' event asynchronously.\n     *\n     * @example\n     *\n     * const speech = require('speech.v1p1beta1');\n     *\n     * const client = new speech.v1p1beta1.SpeechClient({\n     *   // optional auth parameters.\n     * });\n     *\n     * const stream = client.streamingRecognize().on('data', response => {\n     *   // doThingsWith(response)\n     * });\n     * const request = {};\n     * // Write request objects.\n     * stream.write(request);\n     */\n\n  }, {\n    key: \"streamingRecognize\",\n    value: function streamingRecognize(options) {\n      options = options || {};\n      return this._innerApiCalls.streamingRecognize(options);\n    }\n  }], [{\n    key: \"servicePath\",\n    get: function get() {\n      return 'speech.googleapis.com';\n    }\n    /**\n     * The port for this API service.\n     */\n\n  }, {\n    key: \"port\",\n    get: function get() {\n      return 443;\n    }\n    /**\n     * The scopes needed to make gRPC calls for every method defined\n     * in this service.\n     */\n\n  }, {\n    key: \"scopes\",\n    get: function get() {\n      return ['https://www.googleapis.com/auth/cloud-platform'];\n    }\n  }]);\n\n  return SpeechClient;\n}();\n\nmodule.exports = SpeechClient;","map":null,"metadata":{},"sourceType":"script"}