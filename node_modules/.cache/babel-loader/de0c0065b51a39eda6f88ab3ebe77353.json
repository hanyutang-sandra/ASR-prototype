{"ast":null,"code":"/*!\n * Copyright 2017 Google Inc. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n'use strict';\n\nvar common = require('@google-cloud/common');\n\nvar pumpify = require('pumpify');\n\nvar streamEvents = require('stream-events');\n\nvar through = require('through2');\n/*!\n * Return a dictionary-like object with helpers to augment the Speech\n * GAPIC.\n */\n\n\nmodule.exports = function () {\n  var methods = {};\n  /**\n   * Performs bidirectional streaming speech recognition: receive results while\n   * sending audio. This method is only available via the gRPC API (not REST).\n   *\n   * @method v1.SpeechClient#streamingRecognize\n   * @param {object} config The configuration for the stream. This is\n   *     appropriately wrapped and sent as the first argument. It should be an\n   *     object conforming to the [StreamingRecognitionConfig]{@link StreamingRecognitionConfig}\n   *     structure.\n   * @param {object} [options] Optional parameters. You can override the default\n   *     settings for this call, e.g, timeout, retries, paginations, etc. See\n   *     [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions}\n   *     for the details.\n   * @returns {stream} An object stream which is both readable and writable. It\n   *     accepts raw audio for the `write()` method, and will emit objects\n   *     representing [StreamingRecognizeResponse]{@link StreamingRecognizeResponse}\n   *     on the 'data' event asynchronously.\n   *\n   * @example\n   * const speech = require('@google-cloud/speech');\n   * const client = new speech.SpeechClient();\n   *\n   * const stream = client.streamingRecognize({\n   *   config: {\n   *     encoding: 'LINEAR16',\n   *     languageCode: 'en-us',\n   *     sampleRateHertz: 44100,\n   *   },\n   * }).on('data', function(response) {\n   *   // doThingsWith(response);\n   * });\n   * const request = {};\n   * // Write request objects.\n   * stream.write(request);\n   */\n\n  methods.streamingRecognize = function (streamingConfig, options) {\n    options = options || {};\n    streamingConfig = streamingConfig || {}; // Format the audio content as input request for pipeline\n\n    var recognizeStream = streamEvents(pumpify.obj());\n\n    var requestStream = this._innerApiCalls.streamingRecognize(options).on('error', function (err) {\n      recognizeStream.destroy(err);\n    }).on('response', function (response) {\n      recognizeStream.emit('response', response);\n    }); // Attach the events to the request stream, but only do so\n    // when the first write (of data) comes in.\n    //\n    // This also means that the sending of the initial request (with the\n    // config) is delayed until we get the first burst of data.\n\n\n    recognizeStream.once('writing', function () {\n      // The first message should contain the streaming config.\n      requestStream.write({\n        streamingConfig: streamingConfig\n      }); // Set up appropriate piping between the stream returned by\n      // the underlying API method and the one that we return.\n\n      recognizeStream.setPipeline([// Format the user's input.\n      // This entails that the user sends raw audio; it is wrapped in\n      // the appropriate request structure.\n      through.obj(function (audioContent, _, next) {\n        if (audioContent !== undefined) {\n          next(null, {\n            audioContent: audioContent\n          });\n          return;\n        }\n\n        next();\n      }), requestStream, through.obj(function (response, enc, next) {\n        if (response.error) {\n          next(new common.util.ApiError(response.error));\n          return;\n        }\n\n        next(null, response);\n      })]);\n    });\n    return recognizeStream;\n  };\n\n  return methods;\n};","map":null,"metadata":{},"sourceType":"script"}